{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps followed:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". The operaion was performed on 50k train data. \n",
    "\n",
    ". As 69% of data were empty/nan. So, all columns where data was more than 75% empty, were dropped.\n",
    "\n",
    ". The categorical columns were one hot encoded.\n",
    "\n",
    ". And finally, all empty/nan were imputed with softimpute strategy.\n",
    "\n",
    ". The dataset was divided into 3 parts based on the 3 labels to be predicted. (df_train_appetency.csv, df_train_churn.csv, df_train_upselling.csv)\n",
    "\n",
    ". The prediction exercise on 3 labels were separately.\n",
    "\n",
    ". Data Visualization was done with Tsne and Pca, but it did not infer any good visuals.\n",
    "\n",
    ". For all labels, the data was prepared with three strategy- by <b>random upsampling, SMOTE and Near Miss </b>. \n",
    "\n",
    "  The Near Miss downsampling gave very poor result and it was   outrightly rejected. SMOTE and random upsampling gave similar results but random upsampling was preffered.\n",
    "  . Finally, classification was performed on data upsampled and with model's class-weight= balanced.\n",
    "  \n",
    "  . Many classifications such as Logistic Regression, SGDclassifier(log, hinge), Decision tree, Random Forest, xgBoost, KNN and Artificial Neural Network were experimented with.\n",
    "  \n",
    "  . Finally, Logistic Regression along with Decision tree and random forest were zeroed in for predictions for speed.\n",
    "  \n",
    "  . Also added ANN and Voting classifier, but it did not yield better results.\n",
    "  \n",
    "  . Model interprebility was done with LIME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Score:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". Based on unsampled and sampled data, the best auc-roc score for \n",
    "\n",
    ".  appetency was 0.818 \n",
    "\n",
    ". churn 0.713\n",
    "\n",
    ". upselling 0.854\n",
    "\n",
    "which gives an average score of <b>0.795</b>.\n",
    "\n",
    "The score of 0.795 is comparatively good, considering the team (IBM) which won the competition got a score of 0.84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
